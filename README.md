# FLD Generator
This is one of the official repositories of the paper [Learning Deductive Reasoning from Synthetic Corpus based on Formal Logic](https://proceedings.mlr.press/v202/morishita23a.html).
This repository includes the code for generating the FLD corpus.  

See [the entry-point repository](https://github.com/hitachi-nlp/FLD) for the other repositories used in the paper.

## About this release
* This is version 2.0 of FLD corpus generator with improved natural language template quality, logical proof consistency, and harder distractors. This version generates corpora slightly different from those generated by version 1.0 used in the paper.
* See [FLD-corpus](https://github.com/hitachi-nlp/FLD-corpus) for the released corpora and the prover performance.

## Installation
The code has been tested on Python 3.7.7.
```console
$ pip install -r ./requrements.txt
```

## How to generate FLD corpus
Use `./create_corpus.py`, which generates a corpus with the design specified by the option values.

We can create FLD.3 (**FLD**) by running the follows command:
```console
$ python ./create_corpus.py\
    <output_dir>\
    <dataset_size>\
    --depth-range '[1, 3]'\
    --depth-distrib flat\
    --branch-extensions-range '[0, 5]'\
    --argument-config ./configs/arguments/axioms/\
    --complex-formula-arguments-weight 0.5\
    --quantifier-axiom-arguments-weight 0.2\
    --quantifier-axiom universal_quantifier_elim\
    --quantifier-axiom universal_quantifier_intro\
    --quantifier-axiom existential_quantifier_intro\
    --quantifier-axiom existential_quantifier_elim\
    --translation-config ./configs/translations/thing.v1/\
    --distractor "mixture(negative_tree_double.simplified_formula.various_form)"\
    --distractors-range '[0, 20]'\
    --num-workers 5\
    --seed 0
```

We can create FLD.4 (**FLDâ˜…**) by running the follows command:
```console
$ python ./create_corpus.py\
    <output_dir>\
    <dataset_size>\
    --depth-range '[1, 8]'\
    --depth-distrib flat\
    --branch-extensions-range '[0, 5]'\
    --argument-config ./configs/arguments/axioms/\
    --complex-formula-arguments-weight 0.5\
    --quantifier-axiom-arguments-weight 0.2\
    --quantifier-axiom universal_quantifier_elim\
    --quantifier-axiom universal_quantifier_intro\
    --quantifier-axiom existential_quantifier_intro\
    --quantifier-axiom existential_quantifier_elim\
    --translation-config ./configs/translations/thing.v1/\
    --distractor "mixture(negative_tree_double.simplified_formula.various_form)"\
    --distractors-range '[0, 20]'\
    --num-workers 5\
    --seed 0
```

## Citation
```bibtex
@InProceedings{pmlr-v202-morishita23a,
  title = 	 {Learning Deductive Reasoning from Synthetic Corpus based on Formal Logic},
  author =       {Morishita, Terufumi and Morio, Gaku and Yamaguchi, Atsuki and Sogawa, Yasuhiro},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {25254--25274},
  year = 	 {2023},
  editor = 	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume = 	 {202},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {23--29 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v202/morishita23a/morishita23a.pdf},
  url = 	 {https://proceedings.mlr.press/v202/morishita23a.html},
  abstract = 	 {We study a synthetic corpus based approach for language models (LMs) to acquire logical deductive reasoning ability. The previous studies generated deduction examples using specific sets of deduction rules. However, these rules were limited or otherwise arbitrary. This can limit the generalizability of acquired deductive reasoning ability. We rethink this and adopt a well-grounded set of deduction rules based on formal logic theory, which can derive any other deduction rules when combined in a multistep way. We empirically verify that LMs trained on the proposed corpora, which we name $\textbf{FLD}$ ($\textbf{F}$ormal $\textbf{L}$ogic $\textbf{D}$eduction), acquire more generalizable deductive reasoning ability. Furthermore, we identify the aspects of deductive reasoning ability on which deduction corpora can enhance LMs and those on which they cannot. Finally, on the basis of these results, we discuss the future directions for applying deduction corpora or other approaches for each aspect. We release the code, data, and models.}
}
```
