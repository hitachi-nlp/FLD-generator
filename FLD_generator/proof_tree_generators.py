import random
import json
import logging
import math
from collections import defaultdict
from typing import List, Optional, Any, Iterable, Tuple, Dict, Union, Callable, Optional, Set
from pprint import pformat, pprint
import logging

from .formula import (
    PREDICATES,
    CONSTANTS,
    Formula,
    OR,
)
from .formula_checkers import (
    is_predicate_arity_consistent_set as is_predicate_arity_consistent_formula_set,
    is_consistent_set as is_consistent_formula_set,
    is_new as is_formula_new,
)
from .argument import Argument
from .argument_checkers import (
    is_trivial as is_argument_trivial,
    is_nonsense as is_argument_nonsense,
    has_non_canonical_contradiction_use as argument_has_non_canonical_contradiction_use
)
from .interpretation import (
    generate_mappings_from_formula,
    generate_formulas_in_target_space,
    generate_complicated_arguments,
    generate_partially_quantifier_arguments,
    interpret_formula,
    interpret_argument,
    formula_is_identical_to,
    argument_is_identical_to,
    generate_quantifier_axiom_arguments,
)
# from .utils import DelayedLogger
from .proof import ProofTree, ProofNode
from .exception import FormalLogicExceptionBase
from .utils import (
    weighted_shuffle,
    run_with_timeout_retry,
    RetryAndTimeoutFailure,
    make_pretty_msg,
    have_smaller_proofs_with_logs,
    is_consistent_formula_set_with_logs,
)

from .formula import (
    IMPLICATION,
    AND,
    OR,
    NEGATION,
    PREDICATES,
    CONSTANTS,
    VARIABLES,
    has_contradiction_symbol,
)
import kern_profiler

# _LOG_ONLY_WHEN_FAILED = True
logger = logging.getLogger(__name__)


# see  [failure_loop](./docs/axioms_theorems.md)
_DO_HEURISTICS_TO_AVOID_UNIV_INTRO_FAILURE_LOOP = True


def _is_failure_loop_univ_intro_argument(argument: Argument) -> bool:
    return argument.id.find('universal_intro') >= 0\
        and argument.premises[0].rep.find(IMPLICATION) >= 0


class ProofTreeGenerationFailure(FormalLogicExceptionBase):
    pass


class GenerateStemFailure(ProofTreeGenerationFailure):
    pass


class ExtendBranchesFailure(ProofTreeGenerationFailure):
    pass


class ProofTreeGenerationImpossible(FormalLogicExceptionBase):
    pass


class GenerateStemImpossible(ProofTreeGenerationImpossible):
    pass


class ExtendBranchesImpossible(ProofTreeGenerationImpossible):
    pass


class FixIllegalIntermediateConstantFailure(ProofTreeGenerationFailure):
    pass


class FixIllegalIntermediateConstantImpossible(FormalLogicExceptionBase):
    pass


class IllegalIntermediateConstantError(ProofTreeGenerationFailure):
    pass


_REFERENCE_ARGUMENTS = [
    Argument(
        [Formula('{A}')],
        Formula('{A}'),
        {},
        id='reference.pred_only',
    ),
    Argument(
        [Formula('{A}{a}')],
        Formula('{A}{a}'),
        {},
        id='reference.pred_arg',
    ),
]


class ProofTreeGenerator:

    @profile
    def __init__(self,
                 arguments: List[Argument],
                 complicated_arguments_weight=0.0,
                 quantifier_arguments_weight=0.0,
                 quantifier_axiom_arguments_weight=0.0,
                 quantifier_axioms: Optional[List[str]] = None,
                 quantify_implication_premise_conclusion_at_once=False,
                 quantify_all_at_once=True,
                 or_arguments_factor=0.2,  # or is not that impotant for NLI
                 existential_arguments_factor=0.2,  # existential quantifier is not that impotant for NLI
                 universal_arguments_factor=1.0,
                 universal_theorem_argument_factor=1.0,
                 reference_argument_factor=3.0,  # reference argument is impotant
                 elim_dneg=False,
                 disallow_contradiction_as_hypothesis=True):
        if not math.isclose(quantifier_arguments_weight, 0.0):
            raise NotImplementedError('Currently, the arguments generated by generate_partially_quantifier_arguments()'
                                      'such as "(x) Fx -> Ga" is not supported by the translation configuration.')

        self.elim_dneg = elim_dneg
        self.disallow_contradiction_as_hypothesis = disallow_contradiction_as_hypothesis

        self._complicated_arguments_weight = complicated_arguments_weight
        self.arguments, self.argument_weights = self._load_arguments(
            arguments,
            max_PASs_per_formula=3,
            max_implication_per_formula=1,
            max_and_or_per_formula=1,
            complicated_arguments_weight=self._complicated_arguments_weight,
            quantifier_arguments_weight=quantifier_arguments_weight,
            quantifier_axiom_arguments_weight=quantifier_axiom_arguments_weight,
            quantifier_axioms=quantifier_axioms,
            quantify_implication_premise_conclusion_at_once=quantify_implication_premise_conclusion_at_once,
            quantify_all_at_once=quantify_all_at_once,
            allow_generating_heterogeneous_arity_formulas=False,
            or_arguments_factor=or_arguments_factor,
            existential_arguments_factor=existential_arguments_factor,
            universal_arguments_factor=universal_arguments_factor,
            universal_theorem_argument_factor=universal_theorem_argument_factor,
            reference_argument_factor=reference_argument_factor,
            elim_dneg=elim_dneg,
        )

    @property
    def complicated_arguments_weight(self):
        return self._complicated_arguments_weight

    def _load_arguments(self,
                        arguments: List[Argument],
                        max_PASs_per_formula: Optional[int],
                        max_implication_per_formula: Optional[int],
                        max_and_or_per_formula: Optional[int],
                        complicated_arguments_weight: float,
                        quantifier_arguments_weight: float,
                        quantifier_axiom_arguments_weight: float,
                        quantifier_axioms: Optional[List[str]],
                        quantify_implication_premise_conclusion_at_once: bool,
                        quantify_all_at_once: bool,
                        allow_generating_heterogeneous_arity_formulas: bool,
                        or_arguments_factor: float,
                        existential_arguments_factor: float,
                        universal_arguments_factor: float,
                        universal_theorem_argument_factor: float,
                        reference_argument_factor: float,
                        elim_dneg: bool) -> Tuple[List[Argument], List[Argument]]:
        if allow_generating_heterogeneous_arity_formulas:
            raise NotImplementedError()
        logger.info(make_pretty_msg(title='load arguments', status='start', boundary_level=0))

        arguments = _REFERENCE_ARGUMENTS + arguments

        def _is_numbers_ok_formula(formula: Formula) -> bool:
            if max_PASs_per_formula is not None and len(list(formula.PASs)) > max_PASs_per_formula:
                return False
            if max_implication_per_formula is not None and formula.rep.count(IMPLICATION) > max_implication_per_formula:
                return False
            if max_and_or_per_formula is not None and formula.rep.count(AND) + formula.rep.count(OR) > max_and_or_per_formula:
                return False
            return True

        def _is_numbers_ok_argument(argument: Argument) -> bool:
            all_formulas = argument.premises + [argument.conclusion] + list(argument.assumptions.values())
            if any(not _is_numbers_ok_formula(formula) for formula in all_formulas):
                return False
            return True

        complicated_arguments: List[Argument] = []
        if complicated_arguments_weight > 0.0:
            for argument in arguments:
                for complicated_argument, _, name in generate_complicated_arguments(argument,
                                                                                    elim_dneg=elim_dneg,
                                                                                    suppress_op_expansion_if_exists=True,
                                                                                    # suppress_op_expansion_if_exists=False,
                                                                                    get_name=True):
                    if not _is_numbers_ok_argument(complicated_argument):
                        continue
                    if _is_argument_new(complicated_argument, arguments + complicated_arguments):
                        complicated_argument.id += f'.{name}'
                        complicated_arguments.append(complicated_argument)

        quantified_arguments: List[Argument] = []
        if quantifier_arguments_weight > 0.0:
            for argument in arguments + complicated_arguments:
                for quantifier_type in ['universal', 'existential']:
                    for quantifier_argument, _, name in generate_partially_quantifier_arguments(
                            argument,
                            quantifier_type,
                            elim_dneg=elim_dneg,
                            quantify_implication_premise_conclusion_at_once=quantify_implication_premise_conclusion_at_once,
                            quantify_all_at_once_in_a_formula=quantify_all_at_once,  # current translation config does not support formulas such as (x) Ax v Ba
                            get_name=True):
                        if not _is_numbers_ok_argument(quantifier_argument):
                            continue
                        if _is_argument_new(quantifier_argument, arguments + complicated_arguments + quantified_arguments):
                            quantified_arguments.append(quantifier_argument)
                            quantifier_argument.id += f'.{name}'

        quantifier_axiom_arguments: List[Argument] = []
        if quantifier_axiom_arguments_weight > 0.0:
            unique_formulas: List[Formula] = []
            for argument in arguments + complicated_arguments:
                for formula in argument.all_formulas:
                    if all(not formula_is_identical_to(formula, existent_formula) for existent_formula in unique_formulas):
                        unique_formulas.append(formula)

            quantifier_axioms = quantifier_axioms or []
            for axiom_type in quantifier_axioms:

                if axiom_type == 'existential_quantifier_elim':
                    def _generate_quantifier_axiom_arguments(i_formula: int, formula: Formula):
                        for i_other_formula, other_formula in enumerate(unique_formulas):
                            if len(other_formula.variables) > 0:
                                continue
                            if not allow_generating_heterogeneous_arity_formulas:
                                if len(formula.zeroary_predicates) > 0 and len(formula.unary_predicates) > 0:
                                    raise NotImplementedError()
                                if len(other_formula.zeroary_predicates) > 0 and len(other_formula.unary_predicates) > 0:
                                    raise NotImplementedError()
                                if len(formula.zeroary_predicates) > 0 and len(other_formula.unary_predicates) > 0:
                                    continue
                                if len(formula.unary_predicates) > 0 and len(other_formula.zeroary_predicates) > 0:
                                    continue
                            for quantifier_axiom_argument in generate_quantifier_axiom_arguments(
                                    axiom_type,
                                    formula,
                                    id_prefix=f'fomula-{str(i_formula).zfill(6)}.other_fomula-{str(i_other_formula).zfill(6)}',
                                    quantify_implication_premise_conclusion_at_once=quantify_implication_premise_conclusion_at_once,
                                    quantify_all_at_once=quantify_all_at_once,
                                    e_elim_conclusion_formula_prototype=other_formula):
                                yield quantifier_axiom_argument

                else:
                    def _generate_quantifier_axiom_arguments(i_formula: int, formula: Formula):
                        for quantifier_axiom_argument in generate_quantifier_axiom_arguments(
                                axiom_type,
                                formula,
                                id_prefix=f'fomula-{str(i_formula).zfill(6)}',
                                quantify_implication_premise_conclusion_at_once=quantify_implication_premise_conclusion_at_once,
                                quantify_all_at_once=quantify_all_at_once):
                            yield quantifier_axiom_argument

                for i_formula, formula in enumerate(unique_formulas):
                    if len(formula.variables) > 0:
                        continue
                    for quantifier_axiom_argument in _generate_quantifier_axiom_arguments(i_formula, formula):
                        if not _is_numbers_ok_argument(quantifier_axiom_argument):
                            continue
                        if _is_argument_new(quantifier_axiom_argument, arguments + complicated_arguments + quantifier_axiom_arguments):
                            quantifier_axiom_arguments.append(quantifier_axiom_argument)
        # raise

        def calc_argument_weight(argument: Argument) -> float:
            if argument in arguments:
                return 1 / len(arguments) * (1 - complicated_arguments_weight - quantifier_arguments_weight - quantifier_axiom_arguments_weight) if len(arguments) > 0 else None
            elif argument in complicated_arguments:
                return 1 / len(complicated_arguments) * complicated_arguments_weight if len(complicated_arguments) > 0 else None
            elif argument in quantified_arguments:
                return 1 / len(quantified_arguments) * quantifier_arguments_weight if len(quantified_arguments) > 0 else None
            elif argument in quantifier_axiom_arguments:
                return 1 / len(quantifier_axiom_arguments) * complicated_arguments_weight if len(quantifier_axiom_arguments) > 0 else None
            else:
                raise NotImplementedError()

        _arguments = arguments + complicated_arguments + quantified_arguments + quantifier_axiom_arguments
        _argument_weights = {argument: calc_argument_weight(argument) for argument in _arguments}

        def is_or_formula(formula: Formula) -> bool:
            return formula.rep.find(f' {OR} ') >= 0

        def is_or_argument(argument: Argument) -> bool:
            return any(is_or_formula(formula) for formula in argument.all_formulas)

        def is_existential_argument(argument: Argument) -> bool:
            return argument.id.startswith('existential') and not argument.id.startswith('existential_theorem')

        def is_universal_argument(argument: Argument) -> bool:
            return argument.id.startswith('universal') and not argument.id.startswith('universal_theorem')

        def is_universal_theorem_argument(argument: Argument) -> bool:
            return argument.id.startswith('universal_theorem')

        def is_reference_argument(argument: Argument) -> bool:
            return argument.id.startswith('reference')

        _argument_weights = {
            argument: (weight * or_arguments_factor if is_or_argument(argument) else weight)
            for argument, weight in _argument_weights.items()
        }

        _argument_weights = {
            argument: (weight * existential_arguments_factor if is_existential_argument(argument) else weight)
            for argument, weight in _argument_weights.items()
        }

        _argument_weights = {
            argument: (weight * universal_arguments_factor if is_universal_argument(argument) else weight)
            for argument, weight in _argument_weights.items()
        }

        _argument_weights = {
            argument: (weight * universal_theorem_argument_factor if is_universal_theorem_argument(argument) else weight)
            for argument, weight in _argument_weights.items()
        }

        _argument_weights = {
            argument: (weight * reference_argument_factor if is_reference_argument(argument) else weight)
            for argument, weight in _argument_weights.items()
        }

        logger.info(make_pretty_msg(title='load arguments', status='finish', boundary_level=0))
        for argument in _arguments:
            logger.info('weight: %f    %s', _argument_weights[argument], str(argument))

        return _arguments, _argument_weights

    def generate_tree(self,
                      depth: int,
                      branch_extension_steps: int,
                      get_all_trial_results=False,
                      **kwargs) -> Union[ProofTree, List[ProofTree]]:
        trial_result_proof_trees = _generate_tree_with_timeout_retry(
            self.arguments,
            depth,
            branch_extension_steps,
            argument_weights=self.argument_weights,
            elim_dneg=self.elim_dneg,
            disallow_contradiction_as_hypothesis=self.disallow_contradiction_as_hypothesis,
            **kwargs,
        )
        if get_all_trial_results:
            return trial_result_proof_trees
        else:
            return _pick_largest_tree(trial_result_proof_trees)

    def generate_stem(self, depth: int, get_all_trial_results=False, **kwargs) -> Union[ProofTree, List[ProofTree]]:
        trial_result_proof_trees = _generate_stem_with_timeout_retry(
            self.arguments,
            depth,
            argument_weights=self.argument_weights,
            elim_dneg=self.elim_dneg,
            disallow_contradiction_as_hypothesis=self.disallow_contradiction_as_hypothesis,
            **kwargs,
        )
        if get_all_trial_results:
            return trial_result_proof_trees
        else:
            return _pick_largest_tree(trial_result_proof_trees)

    def extend_branches(self,
                        proof_tree: ProofTree,
                        branch_extension_steps: int,
                        get_all_trial_results=False,
                        **kwargs) -> Union[Tuple[ProofTree, int], List[Tuple[ProofTree, int]]]:
        trial_result_proof_trees = _extend_branches_with_timeout_retry(
            proof_tree,
            self.arguments,
            branch_extension_steps,
            argument_weights=self.argument_weights,
            elim_dneg=self.elim_dneg,
            **kwargs,
        )
        if get_all_trial_results:
            return trial_result_proof_trees
        else:
            return sorted(trial_result_proof_trees,
                          key = lambda A_num_step: A_num_step[1])[-1]


def _generate_tree_with_timeout_retry(arguments: List[Argument],
                                      depth: int,
                                      *args,
                                      max_retry=30,
                                      timeout=10,  # 5 + 5
                                      **kwargs) -> List[ProofTree]:
    try:
        trial_result_proof_trees = run_with_timeout_retry(
            _generate_tree,
            func_args = [arguments, depth] + list(args),
            func_kwargs=kwargs,

            should_retry_func=lambda proof_tree: proof_tree.depth < depth,
            should_retry_exception=ProofTreeGenerationFailure,

            max_retry=max_retry,
            timeout_per_trial=timeout,
            best_effort=kwargs.get('best_effort', False),

            logger=logger,
            log_title='generate_tree()',
        )
        return trial_result_proof_trees
    except RetryAndTimeoutFailure as e:
        raise ProofTreeGenerationFailure(str(e))
    # except ProofTreeGenerationImpossible as e:
    #     raise ProofTreeGenerationFailure(str(e))


def _generate_tree(arguments: List[Argument],
                   depth: int,
                   branch_extension_steps: int,
                   argument_weights: Optional[Dict[Argument, float]] = None,
                   depth_1_reference_weight: Optional[float] = None,
                   elim_dneg=False,
                   ng_formulas: Optional[List[Formula]] = None,
                   disallow_contradiction_as_hypothesis=False,
                   allow_reference_arguments_when_depth_1=True,
                   allow_inconsistency=False,
                   allow_smaller_proofs=False,
                   best_effort=False,
                   force_fix_illegal_intermediate_constants=False,
                   allow_illegal_intermediate_constants=False) -> ProofTree:
    proof_tree = _generate_stem(
        arguments,
        depth,
        argument_weights=argument_weights,
        depth_1_reference_weight=depth_1_reference_weight,
        elim_dneg=elim_dneg,
        disallow_contradiction_as_hypothesis=disallow_contradiction_as_hypothesis,
        allow_inconsistency=allow_inconsistency,
        allow_smaller_proofs=allow_smaller_proofs,
        best_effort=best_effort,

        # since the branch extension may recover the illegal intermediate constants.
        force_fix_illegal_intermediate_constants = force_fix_illegal_intermediate_constants if depth == 1 else False,
        allow_illegal_intermediate_constants = allow_illegal_intermediate_constants if depth == 1 else False,
    )
    if depth > 1:
        try:
            trial_results = _extend_branches_with_timeout_retry(
                proof_tree,
                arguments,
                branch_extension_steps,
                argument_weights=argument_weights,
                depth_limit=proof_tree.depth,
                elim_dneg=elim_dneg,
                ng_formulas=ng_formulas,
                allow_inconsistency=allow_inconsistency,
                allow_smaller_proofs=allow_smaller_proofs,
                best_effort=best_effort,
                allow_reference_arguments_when_depth_1=allow_reference_arguments_when_depth_1,
                force_fix_illegal_intermediate_constants=force_fix_illegal_intermediate_constants,
                allow_illegal_intermediate_constants=allow_illegal_intermediate_constants,
                max_retry=10,
            )
            proof_tree = sorted(trial_results,
                                key = lambda A_num_step: A_num_step[1])[-1][0]
        except (ExtendBranchesFailure, ExtendBranchesImpossible) as e:
            logger.warning(make_pretty_msg(title='extend_branches()', status='failure', boundary_level=0,
                                           msg=f'because of the following error:\n{str(e)}'))

            # The following is needed since it is possible that the _extend_branches_with_timeout_retry did nothing.
            proof_tree = _validate_illegal_intermediate_constants(
                force_fix_illegal_intermediate_constants,
                allow_illegal_intermediate_constants,
                ExtendBranchesFailure,
                proof_tree,
                arguments,
                argument_weights=argument_weights,
                allow_inconsistency=allow_inconsistency,
                allow_smaller_proofs=allow_smaller_proofs,
                elim_dneg=elim_dneg,
            )
    return proof_tree


def _pick_largest_tree(proof_trees: List[ProofTree]) -> ProofTree:
    return sorted(proof_trees, key=lambda proof_tree: proof_tree.depth)[-1]


def _generate_stem_with_timeout_retry(arguments: List[Argument],
                                      depth: int,
                                      *args,
                                      max_retry=30,
                                      timeout=5,
                                      best_effort=False,
                                      **kwargs) -> List[ProofTree]:
    try:
        _kwargs = kwargs.copy()
        _kwargs['best_effort'] = best_effort
        return run_with_timeout_retry(
            _generate_stem,
            func_args=[arguments, depth] + list(args),
            func_kwargs=_kwargs,

            should_retry_func=lambda proof_tree: proof_tree.depth < depth,
            should_retry_exception=GenerateStemFailure,

            max_retry=max_retry,
            timeout_per_trial=timeout,
            best_effort=best_effort,

            logger=logger,
            log_title='generate_stem()',
        )
    except RetryAndTimeoutFailure as e:
        raise GenerateStemFailure(str(e))
    # except GenerateStemImpossible as e:
    #     raise GenerateStemFailure(str(e))


def _extend_branches_with_timeout_retry(proof_tree: ProofTree,
                                        arguments: List[Argument],
                                        num_steps: int,
                                        *args,
                                        timeout=5,
                                        max_retry=30,
                                        best_effort=False,
                                        **kwargs) -> List[Tuple[ProofTree, int]]:
    try:
        _kwargs = kwargs.copy()
        _kwargs['best_effort'] = best_effort
        return run_with_timeout_retry(
            _extend_branches,
            func_args=[proof_tree, arguments, num_steps] + list(args),
            func_kwargs=_kwargs,

            should_retry_func = lambda proof_tree_step: proof_tree_step[1] < num_steps,
            should_retry_exception=ExtendBranchesFailure,

            max_retry=max_retry,
            timeout_per_trial=timeout,
            best_effort=best_effort,

            logger=logger,
            log_title='extend_branches()',
        )
    except RetryAndTimeoutFailure as e:
        raise ExtendBranchesFailure(str(e))
    # except ExtendBranchesImpossible as e:
    #     raise ExtendBranchesFailure(str(e))


@profile
def _generate_stem(arguments: List[Argument],
                   depth: int,
                   argument_weights: Optional[Dict[Argument, float]] = None,
                   depth_1_reference_weight: Optional[float] = None,
                   elim_dneg=False,
                   disallow_contradiction_as_hypothesis=False,
                   allow_non_canonical_contradiction_use=False,
                   allow_inconsistency=False,
                   allow_smaller_proofs=False,
                   force_fix_illegal_intermediate_constants=False,
                   allow_illegal_intermediate_constants=False,
                   best_effort=False) -> ProofTree:
    """ Generate stem of proof tree in a top-down manner.

    The steps are:
    (i) Choose an argument.
    (ii) Add the premises of the argument to tree.
    (iii) Choose next argument where one of the premises of the chosen argument is the same as the conclusion of the argument chosen in (i).
    (iv) Add the premises of the argument chosen in (iii)
    (v) Repeat (iii) - (iv).
    """
    if depth < 1:
        raise ValueError('depth must be >= 2')

    def _my_validate_illegal_intermediate_constants(proof_tree: ProofTree) -> ProofTree:
        return _validate_illegal_intermediate_constants(
            force_fix_illegal_intermediate_constants,
            allow_illegal_intermediate_constants,
            GenerateStemFailure,
            proof_tree,
            arguments,
            argument_weights=argument_weights,
            elim_dneg=elim_dneg,
        )

    def update(premise_nodes: List[ProofNode],
               assumption_nodes: List[Optional[ProofNode]],
               conclusion_node: ProofNode,
               argument: Argument,
               proof_tree: ProofTree):

        for premise_node in premise_nodes:
            conclusion_node.add_child(premise_node)

        for assumption_node in assumption_nodes:
            conclusion_node.add_assump_child(assumption_node)

        conclusion_node.argument = argument

        for node in premise_nodes\
                + [node for node in assumption_nodes if node is not None]\
                + [conclusion_node]:
            proof_tree.add_node(node)

    reference_arguments = [arg for arg in arguments if arg.id.startswith('reference')]

    def argument_sampling_reference():
        for arg in _shuffle_arguments(reference_arguments, weights=argument_weights):
            yield arg

    def argument_sampling_non_reference():
        for arg in _shuffle_arguments(arguments, weights=argument_weights):
            if arg.id.startswith('reference'):
                continue
            yield arg

    def argument_sampling_all():
        for arg in _shuffle_arguments(arguments, weights=argument_weights):
            yield arg

    def find_possible_assumption_nodes(node: ProofNode) -> Iterable[ProofNode]:
        for descendant in node.descendants:
            if descendant.is_leaf:
                yield descendant

    def find_linkable_arguments(node: ProofNode) -> Iterable[Argument]:
        cur_possible_assumption_nodes = set(find_possible_assumption_nodes(node))

        for arg in arguments:
            one_premise_matched = False
            for premise in arg.premises:
                if not formula_is_identical_to(premise, node.formula):
                    continue

                if premise in arg.assumptions:
                    assumption = arg.assumptions[premise]
                    if not any(formula_is_identical_to(cur_assumption_node.formula, assumption)
                               for cur_assumption_node in cur_possible_assumption_nodes):
                        continue

                one_premise_matched = True
                break

            if one_premise_matched:
                yield arg

    if depth == 1:
        if depth_1_reference_weight is not None:
            def argument_sampling():
                iter_reference = argument_sampling_reference()
                iter_non_reference = argument_sampling_non_reference()
                while True:
                    rand = random.random()
                    if rand < depth_1_reference_weight:
                        try:
                            arg = next(iter_reference)
                        except StopIteration:
                            iter_reference = argument_sampling_reference()
                            arg = next(iter_reference)
                    else:
                        try:
                            arg = next(iter_non_reference)
                        except StopIteration:
                            iter_non_reference = argument_sampling_non_reference()
                            arg = next(iter_non_reference)
                    yield arg
        else:
            argument_sampling = argument_sampling_all
    else:
        argument_sampling = argument_sampling_non_reference

    for cur_arg in argument_sampling():  # try all the argument as starting point
        if len(cur_arg.assumptions) > 0:
            # the node with assumptions can not be used as the first node.
            continue

        if _DO_HEURISTICS_TO_AVOID_UNIV_INTRO_FAILURE_LOOP\
                and _is_failure_loop_univ_intro_argument(cur_arg):
            continue

        proof_tree = ProofTree()
        cur_conclusion_node = ProofNode(cur_arg.conclusion)
        cur_premise_nodes = [ProofNode(formula) for formula in cur_arg.premises]
        update(cur_premise_nodes, [], cur_conclusion_node, cur_arg, proof_tree)

        is_tree_done = False
        while True:
            log_traces = []
            rejection_stats = defaultdict(int)
            # delayed_logger = DelayedLogger(logger, delayed=_LOG_ONLY_WHEN_FAILED)

            if proof_tree.depth >= depth:
                is_tree_done = True
                break

            formulas_in_tree = [node.formula for node in proof_tree.nodes]

            cur_conclusion = cur_conclusion_node.formula
            cur_possible_assumption_nodes = list(find_possible_assumption_nodes(cur_conclusion_node))
            log_traces.append(f'   | cur_conclusion {cur_conclusion}')

            linkable_args = list(find_linkable_arguments(cur_conclusion_node))

            if len(linkable_args) == 0:
                rejection_stats['len(linkable_args) == 0'] += 1

            # -- find linkable argument --
            is_arg_found = False
            next_arg_pulled = None
            for next_arg in _shuffle_arguments(linkable_args, argument_weights):
                if is_arg_found:
                    break

                log_traces.append(f'   |   | next_arg {next_arg}')

                # Choose mapping
                # The outer loops are for speedup: first build mappings on small variabl set and then use it for filtering out the mappings on large variable set.
                for formula in _shuffle(next_arg.premises):
                    if is_arg_found:
                        break
                    log_traces.append(f'   |   |   | premise {formula}')

                    assumption = next_arg.assumptions.get(formula, None)
                    for premise_mapping in generate_mappings_from_formula(
                        [formula] + ([assumption] if assumption is not None else []),
                        [cur_conclusion] + [node.formula for node in cur_possible_assumption_nodes],
                        shuffle=True,
                    ):
                        if is_arg_found:
                            break

                        premise_pulled = interpret_formula(formula, premise_mapping, elim_dneg=elim_dneg)
                        assumption_pulled = interpret_formula(assumption, premise_mapping, elim_dneg=elim_dneg) if assumption is not None else None
                        log_traces.append(f'   |   |   | premise_pulled {premise_pulled}')
                        log_traces.append(f'   |   |   | assumption_pulled {assumption_pulled}')

                        if premise_pulled.rep != cur_conclusion.rep:  # linkable or not
                            rejection_stats['premise_pulled.rep != cur_conclusion.rep'] += 1
                            continue

                        if assumption_pulled is not None:
                            if all(assumption_pulled.rep != cur_assumption_node.formula.rep
                                   for cur_assumption_node in cur_possible_assumption_nodes):
                                rejection_stats['all(assumption_pulled.rep != cur_assumption_node.formula.rep)'] += 1
                                continue

                        if not is_predicate_arity_consistent_formula_set([premise_pulled] + formulas_in_tree):
                            rejection_stats['not is_predicate_arity_consistent_formula_set([premise_pulled] + formulas_in_tree)'] += 1
                            continue

                        target_preds, target_consts = _choose_target_preds_consts(proof_tree,
                                                                                  next_arg,
                                                                                  constraints=premise_mapping)
                        for i_mapping_trial, mapping in enumerate(
                                generate_mappings_from_formula(
                                    next_arg.all_formulas,
                                    [Formula(' '.join(rep for rep in target_preds + target_consts))],
                                    constraints=premise_mapping,
                                    allow_many_to_one=False,
                                    shuffle=True,
                                )
                        ):
                            if i_mapping_trial >= 1:
                                # only one trial is enough because we have chosen "neccessary and sufficient" target predicates and constraints.
                                # we leave this loop for back reference
                                break

                            if is_arg_found:
                                break

                            next_arg_pulled = interpret_argument(next_arg, mapping, elim_dneg=elim_dneg)

                            if not allow_non_canonical_contradiction_use and argument_has_non_canonical_contradiction_use(next_arg_pulled):
                                # we reject formulas such as "(x): ({A}x & {B}x) -> #F#" due to the folllowing reasons.
                                # (i) we have not yet implemented translations for such formulas
                                # (ii) we have not yet implemented formula checking algorithms for such formulas, due to the technological limitation of z3
                                # Rejecting such formulas does not matter much, because proof by contradiction is not that important in NLP.
                                rejection_stats['argument_has_non_canonical_contradiction_use(next_arg_pulled)'] += 1
                                continue

                            if is_argument_trivial(next_arg_pulled):
                                rejection_stats['is_argument_trivial(next_arg_pulled)'] += 1
                                continue

                            if is_argument_nonsense(next_arg_pulled, allow_detect_tautology_contradiction=True):
                                # is_argument_nonsense(next_arg_pulled, allow_detect_tautology_contradiction=True)
                                rejection_stats['is_argument_nonsense(next_arg_pulled)'] += 1
                                continue

                            if not is_predicate_arity_consistent_formula_set(formulas_in_tree + next_arg_pulled.all_formulas):
                                rejection_stats['is_predicate_arity_consistent_formula_set(next_arg_pulled.all_formulas + formulas_in_tree)'] += 1
                                continue

                            all_new_formulas = [formula for formula in next_arg_pulled.premises + [next_arg_pulled.conclusion]
                                                if formula.rep != cur_conclusion.rep]
                            if not _is_formulas_new(formulas_in_tree, all_new_formulas):
                                rejection_stats['not _is_formulas_new(formulas_in_tree, all_new_formulas)'] += 1
                                continue

                            if _is_argument_negation_elim(next_arg_pulled):
                                # negation elim legally introduces inconsistency, and thus smaller proofs.
                                pass
                            else:
                                org_leaf_formulas = [node.formula for node in proof_tree.leaf_nodes]
                                new_leaf_formulas = [formula for formula in next_arg_pulled.premises if formula.rep != cur_conclusion.rep]
                                deleted_leaf_formulas = list(next_arg_pulled.assumptions.values())
                                org_root_formula = proof_tree.root_node.formula
                                new_root_formula = next_arg_pulled.conclusion

                                if not allow_inconsistency:
                                    _is_consistent, logs = is_consistent_formula_set_with_logs(
                                        org_leaf_formulas,
                                        new_leaf_formulas,
                                        deleted_leaf_formulas,
                                        new_argument=next_arg_pulled,
                                    )
                                    if not _is_consistent:
                                        logger.info('_generate_stem() reject the argument because the proof tree formulas are inconsistent')
                                        for msg in logs:
                                            logger.info(msg)
                                        rejection_stats['_is_consistent_formula_set'] += 1
                                        continue

                                if not allow_smaller_proofs:
                                    _have_smaller_proofs, logs = have_smaller_proofs_with_logs(
                                        org_leaf_formulas,
                                        new_leaf_formulas,
                                        deleted_leaf_formulas,
                                        org_root_formula,
                                        new_root_formula,
                                        new_argument=next_arg_pulled,
                                    )
                                    if _have_smaller_proofs:
                                        logger.info('_generate_stem() reject the argument because the proof tree have smaller proofs')
                                        for log in logs:
                                            logger.info(log)
                                        rejection_stats['_have_smaller_proofs'] += 1
                                        continue

                            is_arg_found = True
                            break

            # -- update tree --
            if is_arg_found:
                # Update
                next_assumption_nodes = []
                for i_premise, formula in enumerate(next_arg_pulled.premises):
                    if formula.rep == cur_conclusion.rep:
                        next_arg_pulled.premises[i_premise] = cur_conclusion  # refer to the unique object.
                    if formula in next_arg_pulled.assumptions:
                        assumption = next_arg_pulled.assumptions[formula]
                        for cur_assumption_node in cur_possible_assumption_nodes:
                            if assumption.rep == cur_assumption_node.formula.rep:
                                next_arg_pulled.assumptions[formula] = cur_assumption_node.formula  # refer to the unique object.
                                next_assumption_nodes.append(cur_assumption_node)

                next_conclusion_node = ProofNode(next_arg_pulled.conclusion)
                next_conclusion_node.argument = next_arg_pulled
                next_premise_nodes = [
                    cur_conclusion_node if formula.rep == cur_conclusion.rep else ProofNode(formula)
                    for formula in next_arg_pulled.premises
                ]
                update(next_premise_nodes, next_assumption_nodes, next_conclusion_node, next_arg_pulled, proof_tree)

                cur_conclusion_node = next_conclusion_node
                cur_premise_nodes = next_premise_nodes

            else:
                rejection_stats_msg = '\n'.join([f'    {line}' for line in pformat(dict(rejection_stats)).split('\n')])
                log_traces_msg = '\n'.join(log_traces)
                msg = '\n'.join([
                    '_generate_stem() failed. The statistics are the followings:',
                    # f'start_arg          :    {start_arg}',  # start_arg is not that informative
                    f'cur_premise_nodes    :    {cur_premise_nodes}',
                    f'cur_conclusion_node  :    {cur_conclusion_node}',

                    'log trace:        :',
                    log_traces_msg,

                    'rejection stats   :',
                    rejection_stats_msg,
                ])
                if best_effort:
                    is_tree_done = True
                    logger.info(msg)
                    logger.info('_generate_stem() could not complete the proof tree with the specified depth. return smaller tree.')
                    break
                else:
                    raise GenerateStemFailure(msg)

        if is_tree_done:

            if disallow_contradiction_as_hypothesis and has_contradiction_symbol(proof_tree.root_node.formula):
                raise GenerateStemFailure(f'formula with contradiction {proof_tree.root_node.formula.rep} as the hypothesis is disallowed.')

            # _check_leaf_consistency(proof_tree)
            proof_tree = _my_validate_illegal_intermediate_constants(proof_tree)

            return proof_tree

    raise Exception('Unexpected')


@profile
def find_linkable_arguments(arguments: List[Argument], node: ProofNode) -> Iterable[Argument]:
    for arg in arguments:

        if _DO_HEURISTICS_TO_AVOID_UNIV_INTRO_FAILURE_LOOP\
                and _is_failure_loop_univ_intro_argument(arg):
            continue

        if formula_is_identical_to(arg.conclusion, node.formula)\
                and len(arg.assumptions) == 0:  # by it's logic, the argument with premise assumptions can not be applied in branch extension
            yield arg


@profile
def _extend_branches(proof_tree: ProofTree,
                     arguments: List[Argument],
                     num_steps: int,
                     start_leaf_nodes: Optional[List[ProofNode]] = None,
                     argument_weights: Optional[Dict[Argument, float]] = None,
                     depth_limit: Optional[int] = None,
                     elim_dneg=False,
                     allow_reference_arguments_when_depth_1=True,
                     ng_formulas: Optional[List[Formula]] = None,
                     allow_illegal_intermediate_constants=False,
                     force_fix_illegal_intermediate_constants=False,
                     allow_inconsistency=False,
                     allow_non_canonical_contradiction_use=False,
                     allow_smaller_proofs=False,
                     best_effort=False,
                     return_alignment=False) -> Union[Tuple[int, ProofTree],
                                                      Tuple[ProofTree, int, Dict[ProofNode, ProcessLookupError]]]:
    """ Extend branches of the proof_tree tree in a bottom-up manner.

    The steps are:
    (i) Choose a leaf node in the tree.
    (ii) Choose an argument where the conclusion of the argument matched the leaf node chosen in (i)
    (iii) Add the psemises of the chosen argument into tree.
    (iv) Repeat (ii) and (iii)
    """

    def _my_validate_illegal_intermediate_constants(proof_tree: ProofTree) -> ProofTree:
        return _validate_illegal_intermediate_constants(
            force_fix_illegal_intermediate_constants,
            allow_illegal_intermediate_constants,
            ExtendBranchesFailure,
            proof_tree,
            arguments,
            argument_weights=argument_weights,
            elim_dneg=elim_dneg,
        )

    orig_leaf_nodes = set(proof_tree.leaf_nodes)
    if start_leaf_nodes is not None:
        for start_leaf_node in start_leaf_nodes:
            if start_leaf_node not in orig_leaf_nodes:
                raise ValueError('start_leaf_node {start_leaf_node} is not a leaf node.')

    proof_tree, orig_nodes_to_copy_nodes = proof_tree.copy(return_alignment=True)
    if start_leaf_nodes is not None:
        start_leaf_nodes = [orig_nodes_to_copy_nodes[orig_node] for orig_node in start_leaf_nodes]

    ng_formulas = ng_formulas or []

    cur_step = 0
    while True:
        if cur_step >= num_steps:
            break

        formulas_in_tree = [node.formula for node in proof_tree.nodes]
        current_leaf_nodes = proof_tree.leaf_nodes

        if start_leaf_nodes is not None:
            # The latter for when the tree is updated
            _target_leaf_nodes = []
            for start_leaf_node in start_leaf_nodes:
                if start_leaf_node.is_leaf:
                    _target_leaf_nodes.append(start_leaf_node)
                else:
                    _target_leaf_nodes.extend([descendant_node
                                               for descendant_node in start_leaf_node.descendants
                                               if descendant_node.is_leaf])

            if len(_target_leaf_nodes) == 0:
                if return_alignment:
                    return proof_tree, cur_step, orig_nodes_to_copy_nodes
                else:
                    return proof_tree, cur_step
        else:
            _target_leaf_nodes = current_leaf_nodes

        if depth_limit is not None:
            _target_leaf_nodes = [node for node in _target_leaf_nodes
                                  if proof_tree.get_node_depth(node) < depth_limit]

        if len(_target_leaf_nodes) == 0:
            logger.warning(make_pretty_msg(title='extend_branches()', status='failure', boundary_level=0,
                                           msg='couldn\'t extend branch because we found no target leaf nodes'))

            # _check_leaf_consistency(proof_tree)

            proof_tree = _my_validate_illegal_intermediate_constants(proof_tree)

            return proof_tree, cur_step

        if cur_step == 0:
            is_linkable_any = False
            for target_node in _target_leaf_nodes:
                for linkable_arg in find_linkable_arguments(arguments, target_node):
                    is_linkable_any = True
                    break
                if is_linkable_any:
                    break
            if not is_linkable_any:
                raise ExtendBranchesImpossible(f'No linkable arguments found for target leaf nodes {str(_target_leaf_nodes)}')

        target_leaf_node = None
        is_leaf_node_done = False
        next_arg_pulled = None
        for leaf_node in _shuffle(_target_leaf_nodes):
            if is_leaf_node_done:
                break

            log_traces = []
            rejection_stats = defaultdict(int)

            log_traces.append(f'   | leaf_node {leaf_node}')

            target_leaf_node = leaf_node

            # Choose next argument
            linkable_args = list(find_linkable_arguments(arguments, leaf_node))
            if len(linkable_args) == 0:
                rejection_stats['len(linkable_args) == 0'] += 1

            is_arg_found = False
            for next_arg in _shuffle_arguments(linkable_args, weights=argument_weights):
                if is_arg_found:
                    is_leaf_node_done = True
                    break

                if next_arg.id.startswith('reference') and (depth_limit != 1 or not allow_reference_arguments_when_depth_1):
                    continue

                log_traces.append(f'   |   | next_arg {next_arg}')

                # Choose mapping
                # The following two nested loop is for speedup:
                # 1. First, we generate the small number of mappings by using small number of symbols. Then, we find appropriate sub-mappings
                # 2. Second, we generate full number of mappings, using the sub-mappings as filters.
                for conclusion_mapping in generate_mappings_from_formula(
                        [next_arg.conclusion],
                        [leaf_node.formula],
                        shuffle=True,
                ):
                    if is_arg_found:
                        break

                    conclusion_pulled = interpret_formula(next_arg.conclusion, conclusion_mapping, elim_dneg=elim_dneg)
                    log_traces.append(f'   |   |   | conclusion_pulled {conclusion_pulled}')

                    if conclusion_pulled.rep != leaf_node.formula.rep:
                        rejection_stats['conclusion_pulled.rep != leaf_node.formula.rep'] += 1
                        continue

                    if not is_predicate_arity_consistent_formula_set([conclusion_pulled] + formulas_in_tree):
                        rejection_stats['not is_predicate_arity_consistent_formula_set([conclusion_pulled] + formulas_in_tree)'] += 1
                        continue

                    target_preds, target_consts = _choose_target_preds_consts(proof_tree,
                                                                              next_arg,
                                                                              constraints=conclusion_mapping)
                    for i_mapping_trial, mapping in enumerate(
                            generate_mappings_from_formula(
                                next_arg.all_formulas,
                                # [Formula(' '.join(constant_pool + predicate_pool))],
                                [Formula(' '.join(rep for rep in target_preds + target_consts))],
                                constraints=conclusion_mapping,
                                allow_many_to_one=False,
                                shuffle=True,
                            )):
                        if i_mapping_trial >= 1:
                            # only one trial is enough because we have chosen "neccessary and sufficient" target predicates and constraints.
                            # we leave this loop for back reference
                            break

                        next_arg_pulled = interpret_argument(next_arg, mapping, elim_dneg=elim_dneg)

                        if not allow_non_canonical_contradiction_use and argument_has_non_canonical_contradiction_use(next_arg_pulled):
                            rejection_stats['argument_has_non_canonical_contradiction_use(next_arg_pulled)'] += 1
                            continue

                        if is_argument_trivial(next_arg_pulled):
                            rejection_stats['is_argument_trivial(next_arg_pulled)'] += 1
                            continue

                        if is_argument_nonsense(next_arg_pulled, allow_detect_tautology_contradiction=True):
                            rejection_stats['is_argument_nonsense(next_arg_pulled)'] += 1
                            continue

                        if not is_predicate_arity_consistent_formula_set(formulas_in_tree + next_arg_pulled.all_formulas):
                            rejection_stats['not is_predicate_arity_consistent_formula_set(next_arg_pulled.all_formulas + formulas_in_tree)'] += 1
                            continue

                        all_new_formulas = next_arg_pulled.premises + list(next_arg_pulled.assumptions.values())
                        if not _is_formulas_new(formulas_in_tree + ng_formulas, all_new_formulas):
                            rejection_stats['not _is_formulas_new(formulas_in_tree, all_new_formulas)'] += 1
                            continue

                        if _is_argument_negation_elim(next_arg_pulled):
                            # negation elim legally introduces inconsistency, and thus smaller proofs.
                            pass
                        else:
                            org_leaf_formulas = [node.formula for node in proof_tree.leaf_nodes]
                            new_leaf_formulas = next_arg_pulled.premises
                            deleted_leaf_formulas = [target_leaf_node.formula] + list(next_arg_pulled.assumptions.values())
                            org_root_formula = proof_tree.root_node.formula
                            new_root_formula = proof_tree.root_node.formula

                            if not allow_inconsistency:
                                _is_consistent, logs = is_consistent_formula_set_with_logs(
                                    org_leaf_formulas,
                                    new_leaf_formulas,
                                    deleted_leaf_formulas,
                                    new_argument=next_arg_pulled,
                                )
                                if not _is_consistent:
                                    logger.info('_extend_branches() reject the argument because the proof tree formulas are inconsistent')
                                    for msg in logs:
                                        logger.info(msg)
                                    rejection_stats['_is_consistent_formula_set'] += 1
                                    continue

                            if not allow_smaller_proofs:
                                _have_smaller_proofs, logs = have_smaller_proofs_with_logs(
                                    org_leaf_formulas,
                                    new_leaf_formulas,
                                    deleted_leaf_formulas,
                                    org_root_formula,
                                    new_root_formula,
                                    new_argument=next_arg_pulled,
                                )
                                if _have_smaller_proofs:
                                    logger.info('_extend_branches() reject the argument because the proof tree have smaller proofs')
                                    for log in logs:
                                        logger.info(log)
                                    rejection_stats['_have_smaller_proofs'] += 1
                                    continue

                        is_arg_found = True
                        break

        if is_leaf_node_done:
            # Upate tree
            next_arg_pulled.conclusion = target_leaf_node.formula  # refer to the same object
            target_leaf_node.argument = next_arg_pulled
            next_premise_nodes = [ProofNode(premise)
                                  for premise in next_arg_pulled.premises]
            for premise_node in next_premise_nodes:
                proof_tree.add_node(premise_node)
                target_leaf_node.add_child(premise_node)
            cur_step += 1

        else:
            rejection_stats_msg = '\n'.join([f'    {line}' for line in pformat(dict(rejection_stats)).split('\n')])
            log_traces_msg = '\n'.join(log_traces)
            msg = '\n'.join([
                '_extend_branches() failed. The statistics are the followings:',
                f'leaf_node:    {leaf_node}',

                'log trace:        :',
                log_traces_msg,

                'rejection stats   :',
                rejection_stats_msg,

            ])
            logger.info(msg)
            if best_effort:
                logger.info(msg)
                logger.info('_extend_branches() could not complete the proof tree with the specified steps. return smaller tree.')
                break
            else:
                raise ExtendBranchesFailure(msg)

    # _check_leaf_consistency(proof_tree)
    proof_tree = _my_validate_illegal_intermediate_constants(proof_tree)

    if return_alignment:
        return proof_tree, cur_step, orig_nodes_to_copy_nodes
    else:
        return proof_tree, cur_step


@profile
def _choose_target_preds_consts(proof_tree: ProofTree,
                                next_arg: Argument,
                                constraints: Optional[Dict[str, str]] = None) -> Tuple[List[str], List[str]]:
    tree_preds = {pred.rep
                  for node in proof_tree.nodes
                  for pred in node.formula.predicates}

    tree_consts = {const.rep
                   for node in proof_tree.nodes
                   for const in node.formula.constants}

    constraints = constraints or {}
    constrained_tgt_preds = {pred.rep for rep in constraints.values() for pred in Formula(rep).predicates}
    constrained_tgt_consts = {const.rep for rep in constraints.values() for const in Formula(rep).constants}

    unconstraned_src_preds = {pred.rep for formula in next_arg.all_formulas
                              for pred in formula.predicates if pred.rep not in constraints}
    unconstraned_src_consts = {const.rep for formula in next_arg.all_formulas
                               for const in formula.constants if const.rep not in constraints}

    already_used_preds = tree_preds.union(constrained_tgt_preds)
    already_used_consts = tree_consts.union(constrained_tgt_consts)

    vacant_preds = [pred for pred in PREDICATES if pred not in already_used_preds]  # list for sorting
    vacant_consts = [const for const in CONSTANTS if const not in already_used_consts]  # list for sorting

    tgt_preds = vacant_preds[:len(unconstraned_src_preds)] + list(constrained_tgt_preds)
    tgt_consts = vacant_consts[:len(unconstraned_src_consts)] + list(constrained_tgt_consts)

    return tgt_preds, tgt_consts


def _is_argument_new(argument: Argument, arguments: List[Argument]) -> bool:
    is_already_added = False
    for existent_argument in arguments:
        if argument_is_identical_to(argument, existent_argument):
            logger.info(make_pretty_msg(boundary_level=0,
                                        msg='argument is identical to the already added argument. will be skipped.'))
            logger.info('tried to add  : %s', str(argument))
            logger.info('already added : %s', str(existent_argument))
            is_already_added = True
            break
    return not is_already_added


def _is_formulas_new(formulas: List[Formula], existing_formulas: List[Formula]) -> bool:
    return all((is_formula_new(existing_formulas, formula)
                for formula in formulas))


def _shuffle(elems: List[Any],
             weights: Optional[List[float]] = None) -> Iterable[Any]:
    if weights is None:
        yield from random.sample(elems, len(elems))
    else:
        for idx in weighted_shuffle(weights):
            yield elems[idx]


def _shuffle_arguments(arguments: List[Argument],
                       weights: Optional[Dict[Argument, float]] = None) -> Iterable[Argument]:
    _weights = [weights[argument] for argument in arguments] if weights is not None else None
    yield from _shuffle(arguments, weights=_weights)


# def _check_leaf_consistency(proof_tree: ProofTree) -> None:
#     # We have checked the consistency of the leaf nodes at each step, thus, the leaf nodes must be consistent at the end.
#     # assert is_consistent_formula_set([node.formula for node in proof_tree.leaf_nodes])
#     assert is_consistent_formula_set([node.formula for node in proof_tree.leaf_nodes])


# def _is_intermediate_constants_used(next_arg_pulled: Argument,
#                                     proof_tree: ProofTree) -> Tuple[bool, Optional[str], Optional[ProofNode]]:
#     for constant in next_arg_pulled.intermediate_constants:
#         for leaf_node in proof_tree.leaf_nodes:
#             if constant.rep in [leaf_constant.rep for leaf_constant in leaf_node.formula.constants]:
#                 return True, constant.rep, leaf_node
#     return False, None, None


@profile
def _fix_illegal_intermediate_constants(
    proof_tree: ProofTree,
    arguments: Optional[List[Argument]] = None,
    argument_weights: Optional[Dict[Argument, float]] = None,
    argument_weight_bias_factor=100,
    allow_inconsistency=False,
    allow_smaller_proofs=False,
    elim_dneg=False,
) -> ProofTree:
    if len(list((_find_illegal_intermediate_constants(proof_tree)))) >= 3:
        raise FixIllegalIntermediateConstantImpossible('We do not fix tree with more than 3 illegal node because it is unlikely this fix will succeed, or otherwise it is too slow.')

    if argument_weights is not None:

        def get_biase_fator(argument_id: str) -> float:
            if argument_id.find('universal_elim') >= 0:
                return argument_weight_bias_factor
            elif argument_id.find('universal_intro') >= 0:
                return 1 / argument_weight_bias_factor
            else:
                return 1.0

        argument_weights_biased: Dict[Argument, float] = {
            argument: weight * get_biase_fator(argument.id)
            for argument, weight in argument_weights.items()
        }
        _weight_sum = sum(argument_weights_biased.values())

        for argument, weight in argument_weights_biased.items():
            argument_weights_biased[argument] = weight / _weight_sum
    else:
        argument_weights_biased = {argument: 1.0 / len(arguments)
                                   for argument in arguments}

    def _make_pretty_msg(*args, **kwargs) -> str:
        return make_pretty_msg(*args, title='_fix_illegal_intermediate_constants()', **kwargs)

    logger.info(_make_pretty_msg(status='start', boundary_level=3))

    original_depth = proof_tree.depth

    def find_one_illegal_constant(_proof_tree: ProofTree) -> Tuple[Optional[Formula],
                                                                   Optional[ProofNode]]:
        for constant, illegal_node in _find_illegal_intermediate_constants(_proof_tree):
            return constant, illegal_node
        return None, None

    def is_fixed(constant: Formula, illegal_node: ProofNode, proof_tree_tmp: ProofTree) -> bool:
        descendant_leaf_nodes = [
            node for node in illegal_node.descendants
            if node in proof_tree_tmp.leaf_nodes
        ]
        return all(node.formula.rep.find(constant.rep) < 0 for node in descendant_leaf_nodes)

    def build_exception_msg(illegal_node: ProofNode, node_type: str, constant: Formula, postfix='') -> str:
        return f'fixing a illegal leaf node {str(illegal_node)} with intermediate constant "{constant.rep}" failed' + postfix

    proof_tree_fixed = proof_tree.copy()
    fix_trial_per_node = 30
    all_is_fixed = False
    while True:
        node_is_fixed = False
        for i_trial in range(0, fix_trial_per_node):
            proof_tree_tmp, fixed_nodes_to_tmp_nodes = proof_tree_fixed.copy(return_alignment=True)
            leaf_nodes = set(proof_tree_tmp.leaf_nodes)

            constant, illegal_node = find_one_illegal_constant(proof_tree_tmp)
            if constant is None:  # fixed all
                all_is_fixed = True
                break

            def _make_pretty_msg_for_fix(status: Optional[str] = None, msg: Optional[str] = None) -> str:
                return _make_pretty_msg(trial=i_trial, status=status,
                                        subtitle=f'node={str(illegal_node)}, constant="{str(constant.rep)}"',
                                        max_trial=fix_trial_per_node, boundary_level=1,
                                        msg=msg)

            if illegal_node in leaf_nodes:
                num_steps = i_trial / 6 + 1
                try:
                    trial_results = _extend_branches_with_timeout_retry(
                        proof_tree_tmp,
                        arguments,
                        num_steps,

                        argument_weights=argument_weights_biased,
                        depth_limit=None,
                        start_leaf_nodes=[illegal_node],
                        elim_dneg=elim_dneg,

                        allow_inconsistency=allow_inconsistency,
                        allow_smaller_proofs=allow_smaller_proofs,
                        allow_reference_arguments_when_depth_1=False,

                        force_fix_illegal_intermediate_constants=False,
                        allow_illegal_intermediate_constants=True,
                        return_alignment=True,

                        best_effort=True,
                        timeout=5,
                        max_retry=5,
                    )
                    proof_tree_tmp_maybe_fixed, _, alignment = sorted(trial_results, key=lambda A_num_step_B: A_num_step_B[1])[-1]
                except ExtendBranchesFailure as e:
                    logger.info(_make_pretty_msg_for_fix(status='failure', msg=f'will try next. failed in branch extension due to:\n{str(e)}'))
                    continue
                except ExtendBranchesImpossible as e:
                    raise FixIllegalIntermediateConstantImpossible(
                        _make_pretty_msg(status='failure', msg=f'the original error:\n{str(e)}')
                    )

            elif illegal_node is proof_tree.root_node:
                # TODO: implement here using _generate_stem() with universal_intro arguments
                raise FixIllegalIntermediateConstantImpossible(_make_pretty_msg_for_fix(msg='because the fix for a root node is not implement yet'))
            else:
                raise Exception()

            if is_fixed(constant, alignment[illegal_node], proof_tree_tmp_maybe_fixed):
                logger.info(_make_pretty_msg_for_fix(status='success'))
                node_is_fixed = True
                proof_tree_fixed = proof_tree_tmp_maybe_fixed
                break
            else:
                logger.info(_make_pretty_msg_for_fix(status='failure', msg='will try next. succeeded in branch extension but not in fixing the illegality.'))

        if all_is_fixed:
            break

        if not node_is_fixed:
            raise FixIllegalIntermediateConstantFailure(
                _make_pretty_msg(status='failure')
            )

    if proof_tree_fixed.depth != original_depth:
        logger.warning(_make_pretty_msg(msg=f'altered the depth of the tree from {original_depth} -> {proof_tree_fixed.depth}'))

    logger.info(_make_pretty_msg(status='success', boundary_level=3))

    return proof_tree_fixed


@profile
def _validate_illegal_intermediate_constants(
    force_fix_illegal_intermediate_constants: bool,
    allow_illegal_intermediate_constants: bool,
    exception_cls,
    proof_tree: ProofTree,
    arguments: List[Argument],
    argument_weights: Optional[Dict[Argument, float]] = None,
    allow_inconsistency=False,
    allow_smaller_proofs=False,
    elim_dneg=False
) -> ProofTree:

    if force_fix_illegal_intermediate_constants:
        is_illegal, msg = _is_intermediate_constants_illegal(proof_tree)
        if is_illegal:
            try:
                proof_tree = _fix_illegal_intermediate_constants(
                    proof_tree,
                    arguments=arguments,
                    argument_weights=argument_weights,
                    allow_inconsistency=allow_inconsistency,
                    allow_smaller_proofs=allow_smaller_proofs,
                    elim_dneg=elim_dneg,
                )
            except (FixIllegalIntermediateConstantFailure, FixIllegalIntermediateConstantImpossible) as e:
                raise exception_cls('_fix_illegal_intermediate_constants() failed. the original message is:' + '\n' + str(e))

    if not allow_illegal_intermediate_constants:
        is_illegal, msg = _is_intermediate_constants_illegal(proof_tree)
        if is_illegal:
            raise ExtendBranchesFailure(msg)

    return proof_tree


def _is_intermediate_constants_illegal(
    proof_tree: ProofTree,
) -> Tuple[bool, Optional[str]]:

    leaf_nodes = set(proof_tree.leaf_nodes)

    for constant, illegal_node in _find_illegal_intermediate_constants(proof_tree):
        if illegal_node in leaf_nodes:
            return True, f'The intermediate constant {constant.rep} is used at a leaf node {str(illegal_node)}.'
        elif illegal_node is proof_tree.root_node:
            return True, f'The intermediate constant {constant.rep} is used at the root node {str(illegal_node)}.'
        else:
            raise Exception()
    return False, None


def _find_illegal_intermediate_constants(proof_tree: ProofTree) -> Iterable[Tuple[Formula, ProofNode]]:
    for constant in proof_tree.intermediate_constants:
        for leaf_node in proof_tree.leaf_nodes:
            if constant.rep in [leaf_constant.rep for leaf_constant in leaf_node.formula.constants]:
                yield constant, leaf_node

    root_node = proof_tree.root_node
    if root_node is not None:
        for constant in proof_tree.intermediate_constants:
            if constant.rep in [root_constant.rep for root_constant in root_node.formula.constants]:
                yield constant, leaf_node


def load_arguments(config_paths: List[str]) -> List[Argument]:
    arguments = []
    for config_path in config_paths:
        arguments.extend([Argument.from_json(json_obj)
                          for json_obj in json.load(open(config_path))
                          if not json_obj['id'].startswith('__')])
    return arguments


def _is_argument_negation_elim(arg: Argument) -> bool:
    return arg.id.find('negation_elim') >= 0


def _is_argument_negation_intro(arg: Argument) -> bool:
    return arg.id.find('negation_intro') >= 0


def build(config_paths: List[str],
          complication=0.0,
          quantification=0.0,
          **kwargs):
    arguments = load_arguments(config_paths)
    generator = ProofTreeGenerator(
        arguments,
        complicated_arguments_weight=complication,
        quantifier_axiom_arguments_weight=quantification,
        **kwargs,
    )
    return generator
